{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76fbaf88-5952-47bf-a68c-85011e49b6de",
   "metadata": {},
   "source": [
    "# Building our First RAG bot - Skill: talk to Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c3b06-c8a0-45db-be9a-974c762ba4b8",
   "metadata": {},
   "source": [
    "We have now all the building blocks to build our first Bot that \"talks with my data\". These blocks are:\n",
    "\n",
    "1) A well indexed hybrid (text and vector) engine with my data in chunks -> Azure AI Search\n",
    "2) A good LLM python framework to build LLM Apps -> LangChain\n",
    "3) Quality OpenAI GPT models that understand language and follow instructions -> GPT3.5 and GPT4\n",
    "4) A persisten memory database -> CosmosDB\n",
    "\n",
    "We are missing just one thing: **Agents**.\n",
    "\n",
    "In this Notebook we introduce the concept of Agents and we use it to build or first RAG bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b64f701d-5b9d-4c7c-b259-c2a515c75961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import asyncio\n",
    "from typing import Dict, List\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.runnables import ConfigurableField, ConfigurableFieldSpec\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory, CosmosDBChatMessageHistory\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils import  GetDocSearchResults_Tool\n",
    "from common.prompts import AGENT_DOCSEARCH_PROMPT\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4163af7-39d0-43b4-8dad-c13108d22a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33836104-822e-4846-8b81-0de8e24838f1",
   "metadata": {},
   "source": [
    "## Introducing: Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fc3d38-93f8-4a47-8125-d1bb9f529178",
   "metadata": {},
   "source": [
    "The implementation of Agents is inspired by two papers: the [MRKL Systems](https://arxiv.org/abs/2205.00445) paper (pronounced â€˜miracleâ€™ ðŸ˜‰) and the [ReAct](https://arxiv.org/abs/2210.03629) paper.\n",
    "\n",
    "Agents are a way to leverage the ability of LLMs to understand and act on prompts. In essence, an Agent is an LLM that has been given a very clever initial prompt. The prompt tells the LLM to break down the process of answering a complex query into a sequence of steps that are resolved one at a time.\n",
    "\n",
    "Agents become really cool when we combine them with â€˜expertsâ€™, introduced in the MRKL paper. Simple example: an Agent might not have the inherent capability to reliably perform mathematical calculations by itself. However, we can introduce an expert - in this case a calculator, an expert at mathematical calculations. Now, when we need to perform a calculation, the Agent can call in the expert rather than trying to predict the result itself. This is actually the concept behind [ChatGPT Pluggins](https://openai.com/blog/chatgpt-plugins).\n",
    "\n",
    "In our case, in order to solve the problem \"How do I build a smart bot that talks to my data\", we need this REACT/MRKL approach, in which we need to instruct the LLM that it needs to use 'experts/tools' in order to read/load/understand/interact with a any particular source of data.\n",
    "\n",
    "Let's create then an Agent that interact with the user and uses a Tool to get the information from the Search engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7999a06-aff0-4d21-8be7-fe56c70082a8",
   "metadata": {},
   "source": [
    "#### We start first defining the Tool/Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a862366b-ce9e-44f8-9610-84ec568653ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1_name = \"cogsrch-index-files\"\n",
    "index2_name = \"cogsrch-index-csv\"\n",
    "index3_name = \"cogsrch-index-books\"\n",
    "indexes = [index1_name, index2_name, index3_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077886c8-c5d0-481d-a5f9-f4becf60e0f9",
   "metadata": {},
   "source": [
    "We have to convert the Retreiver object into a Tool object (\"the expert\"). Check out the Tool `GetDocSearchResults_Tool` in `utils.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73c6ca7-d93b-4961-b90a-08572cad78d8",
   "metadata": {},
   "source": [
    "Declare the tools the agent will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a0fd3a0-527c-42e3-a092-46e03d33bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "topK=7\n",
    "tools = [GetDocSearchResults_Tool(indexes=indexes, k=5, reranker_th=1, sas_token=os.environ['BLOB_SAS_TOKEN'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cac295-8be5-4803-8342-6d4e48cd2294",
   "metadata": {},
   "source": [
    "Get the prompt to use `AGENT_DOCSEARCH_PROMPT` - you can modify this in `prompts.py`! Check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a44f8df6-a68e-4215-99f3-10119f796c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = AGENT_DOCSEARCH_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ddf18-3f3c-44b4-8af5-1437973da010",
   "metadata": {},
   "source": [
    "Define the LLM to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5aaaf7f5-ef26-48d8-868d-b53aa4c4f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_TOKENS = 1500\n",
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS, streaming=True).configurable_alternatives(\n",
    "    ConfigurableField(id=\"model\"),\n",
    "    default_key=\"gpt35\",\n",
    "    gpt4=AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS, streaming=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d527c12-4e18-4f3f-a9ec-8dab4f9ca7b2",
   "metadata": {},
   "source": [
    "Construct the OpenAI Tools agent.\n",
    "> OpenAI API has deprecated functions in favor of tools. The difference between the two is that the tools API allows the model to request that multiple functions be invoked at once, which can reduce response times in some architectures. Itâ€™s recommended to use the tools agent for OpenAI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6fff2766-defb-45fc-b271-3c811077076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm.with_config(configurable={\"model\": \"gpt35\"}), tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338336d9-a64a-4602-908a-742b418e4520",
   "metadata": {},
   "source": [
    "Create an agent executor by passing in the agent and tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad6c156f-9a17-4daa-80de-70ce2f55063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a017c-3b36-43ab-8633-78f4f005d166",
   "metadata": {},
   "source": [
    "Give it memory - since AgentExecutor is also a Runnable class, we do the same with did on Notebook 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c013314-afe6-4218-b179-d0f7312d2670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str, user_id: str) -> CosmosDBChatMessageHistory:\n",
    "    cosmos = CosmosDBChatMessageHistory(\n",
    "        cosmos_endpoint=os.environ['AZURE_COSMOSDB_ENDPOINT'],\n",
    "        cosmos_database=os.environ['AZURE_COSMOSDB_NAME'],\n",
    "        cosmos_container=os.environ['AZURE_COSMOSDB_CONTAINER_NAME'],\n",
    "        connection_string=os.environ['AZURE_COMOSDB_CONNECTION_STRING'],\n",
    "        session_id=session_id,\n",
    "        user_id=user_id\n",
    "        )\n",
    "\n",
    "    # prepare the cosmosdb instance\n",
    "    cosmos.prepare_cosmos()\n",
    "    return cosmos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df017f-3ab7-4943-adc1-3477badf3d3e",
   "metadata": {},
   "source": [
    "Because cosmosDB needs two fields (an id and a partition), and RunnableWithMessageHistory takes by default only one identifier for memory (session_id), we need to use `history_factory_config` parameter and define the multiple keys for the memory class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf93758f-da3b-48fb-9882-91fe327b1751",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_spec = ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        )\n",
    "session_id = ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "52d1aaa6-efca-4512-b680-896dae39a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[userid_spec,session_id]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "05c6b489-3db9-4965-9eae-ed2790e62bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'session922', 'user_id': 'user260'}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configure the session id and user id\n",
    "random_session_id = \"session\"+ str(random.randint(1, 1000))\n",
    "ramdom_user_id = \"user\"+ str(random.randint(1, 1000))\n",
    "\n",
    "config={\"configurable\": {\"session_id\": random_session_id, \"user_id\": ramdom_user_id}}\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3295c54e-a5e2-46f6-99fc-6f76453a877d",
   "metadata": {},
   "source": [
    "Run the Agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2ac81763-6bcc-4408-9daf-d047a0e2cb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 215 ms, sys: 208 Âµs, total: 216 ms\n",
      "Wall time: 1.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': \"Hi, I'm Pablo Marin. What's yours\",\n",
       " 'history': [],\n",
       " 'output': \"Hello Pablo Marin, I'm Jarvis. How can I assist you today?\"}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "agent_with_chat_history.invoke({\"question\": \"Hi, I'm Pablo Marin. What's yours\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cb3fca7e-33a1-40f1-afb0-dee441a1d1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Markov chains are a mathematical concept used to model a system that transitions from one state to another according to certain probabilistic rules. In the context of medicine, there are several applications of Markov chains:\n",
       "\n",
       "1. **Particle Transport in Enclosed Environments:**\n",
       "   - A combined computational fluid dynamics (CFD) and Markov chain method was developed to predict transient particle transport in enclosed environments. This method involved calculating a transition probability matrix using CFD simulations and then applying the Markov chain technique to calculate transient particle concentration distributions. It was validated in various cases, including particle transport in an isothermal clean room, an office with an underfloor air distribution system, and the first-class cabin of an MD-82 airliner<sup><a href=\"https://doi.org/10.1111/ina.12056\" target=\"_blank\">source</a></sup>.\n",
       "\n",
       "2. **Spread of Viruses:**\n",
       "   - A spatial Markov Chain model was used to model the spread of viruses. The model is based on representing a graph connecting nodes, which represent humans, and the vertices between the nodes represent relations between humans. The likelihood of infectious spread from person to person is determined by the intensity of interpersonal contact, and infectious transfer is determined by chance. The model is extended to incorporate various lockdown scenarios<sup><a href=\"https://arxiv.org/pdf/2004.05635v1.pdf\" target=\"_blank\">source</a></sup>.\n",
       "\n",
       "3. **Fast Prediction of Transient Particle Transport:**\n",
       "   - A combined fast fluid dynamics (FFD) and Markov chain model was proposed for fast predicting transient particle transport indoors. The solver for the FFD-Markov-chain model was programmed in OpenFOAM, an open-source CFD toolbox. The model was validated and found to greatly reduce the computing cost for predicting transient particle transport in indoor environments<sup><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7090511/\" target=\"_blank\">source</a></sup>.\n",
       "\n",
       "These applications demonstrate the versatility of Markov chains in modeling and predicting various phenomena in the field of medicine.\n",
       "\n",
       "References:\n",
       "1. [Particle Transport in Enclosed Environments](https://doi.org/10.1111/ina.12056)\n",
       "2. [Spread of Viruses](https://arxiv.org/pdf/2004.05635v1.pdf)\n",
       "3. [Fast Prediction of Transient Particle Transport](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7090511/)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(agent_with_chat_history.invoke(\n",
    "    {\"question\": \"What are markov chains and is there an application in medicine?\"}, \n",
    "    config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c430c456-f390-4319-a3b1-bee19da130cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In the context of the spread of viruses, Markov chains have been applied in several ways:\n",
       "\n",
       "1. **Spatial Markov Chain Model:**\n",
       "   - A spatial Markov Chain model was developed to model the spread of viruses. This model is based on representing a graph connecting nodes, which represent humans, and the vertices between the nodes represent relations between humans. The likelihood of infectious spread from person to person is determined by the intensity of interpersonal contact, and infectious transfer is determined by chance. The model is extended to incorporate various lockdown scenarios, providing a framework for understanding and predicting the spread of viruses within human populations<sup><a href=\"https://arxiv.org/pdf/2004.05635v1.pdf\" target=\"_blank\">source</a></sup>.\n",
       "\n",
       "2. **Stochastic Epidemic Models with Two Groups:**\n",
       "   - Continuous-time Markov chain (CTMC) models have been applied to study disease emergence or re-emergence from different groups, where the transmission rates depend on either the infectious host or the susceptible host. These models have been used to estimate the probability of a minor or a major epidemic, and have been applied to diseases such as Severe Acute Respiratory Syndrome (SARS) and measles. This approach provides insights into the dynamics of disease spread and the factors influencing the likelihood of major epidemics<sup><a href=\"https://doi.org/10.1080/17513758.2018.1538462\" target=\"_blank\">source</a></sup>.\n",
       "\n",
       "3. **Nonlinear Markov Chains Model for Covid-19 Pandemic:**\n",
       "   - A nonlinear Markov chains model was proposed to analyze and understand the behavior of the Covid-19 pandemic. This model was used to estimate the daily new Covid-19 cases in various countries and to examine the correlation between the daily new Covid-19 cases and the daily number of deaths. The model provided insights into the dynamics of the pandemic and its impact on different regions<sup><a href=\"http://medrxiv.org/cgi/content/short/2020.04.21.20073668v1?rss=1\" target=\"_blank\">source</a></sup>.\n",
       "\n",
       "These applications highlight the use of Markov chains in modeling and understanding the spread of viruses, providing valuable insights for public health and epidemic management.\n",
       "\n",
       "References:\n",
       "1. [Spatial Markov Chain Model](https://arxiv.org/pdf/2004.05635v1.pdf)\n",
       "2. [Stochastic Epidemic Models with Two Groups](https://doi.org/10.1080/17513758.2018.1538462)\n",
       "3. [Nonlinear Markov Chains Model for Covid-19 Pandemic](http://medrxiv.org/cgi/content/short/2020.04.21.20073668v1?rss=1)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    printmd(agent_with_chat_history.invoke(\n",
    "        {\"question\": \"Interesting, Tell me more about the use specifically in the spread of viruses\"},\n",
    "        config=config)[\"output\"])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9fd54f71-03c9-4332-885b-0d1df942fa88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You're welcome! If you have any more questions or if there's anything else I can help you with, feel free to ask."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(agent_with_chat_history.invoke({\"question\": \"Thhank you!\"}, config=config)[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149648ba-945d-4e7d-81f7-a8bca2ac87f2",
   "metadata": {},
   "source": [
    "#### Important: there is a limitation of GPT3.5, once we start adding long prompts, and long contexts and thorough answers, or the agent makes multiple searches for multi-step questions, we run out of space!\n",
    "\n",
    "You can minimize this by:\n",
    "- Shorter System Prompt\n",
    "- Smaller chunks (less than the default of 5000 characters)\n",
    "- Reducing topK to bring less relevant chunks\n",
    "\n",
    "However, you ultimately are sacrificing quality to make everything work with GPT3.5 (cheaper and faster model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41787714-73fd-4336-85f2-bec3abb41eda",
   "metadata": {},
   "source": [
    "### Let's add more things we have learned so far: dynamic LLM selection of GPT4 and asyncronous streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1511d2c3-97fe-4232-a560-014d0f157008",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm.with_config(configurable={\"model\": \"gpt4\"}), tools, prompt) # We select now GPT-4\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
    "agent_with_chat_history = RunnableWithMessageHistory(agent_executor,get_session_history,input_messages_key=\"question\", \n",
    "                                                     history_messages_key=\"history\", history_factory_config=[userid_spec,session_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec5b32-6017-44b9-97e7-34ba3695e688",
   "metadata": {},
   "source": [
    "In prior notebooks with use the function `.stream()` of the runnable in order to stream the tokens. However if you need to stream individual tokens from the agent or surface steps occuring within tools, you would need to use a combination of `Callbacks` and `.astream()` OR the new `astream_events` API (beta).\n",
    "\n",
    "Letâ€™s use here the astream_events API to stream the following events:\n",
    "\n",
    "    Agent Start with inputs\n",
    "    Tool Start with inputs\n",
    "    Tool End with outputs\n",
    "    Stream the agent final anwer token by token\n",
    "    Agent End with outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9600a35e-8d2e-43d0-a334-092b2e8b832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Tell me more about your last answer, search again multiple times and provide a deeper explanation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3808fa33-05bb-4f5d-9ab9-7159f6db62a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting agent: AgentExecutor\n",
      "--\n",
      "Starting tool: docsearch with inputs: {'query': 'spatial Markov Chain model virus spread'}\n",
      "--\n",
      "Starting tool: docsearch with inputs: {'query': 'continuous-time Markov chain (CTMC) models disease spread'}\n",
      "--\n",
      "Starting tool: docsearch with inputs: {'query': 'nonlinear Markov chains model Covid-19 pandemic'}\n",
      "Done tool: docsearch\n",
      "--\n",
      "Done tool: docsearch\n",
      "--\n",
      "Done tool: docsearch\n",
      "--\n",
      "Upon further research, we can provide a more detailed explanation of the application of Markov chains in the spread of viruses, focusing on the spatial Markov Chain model and its relevance to the Covid-19 pandemic.\n",
      "\n",
      "### Spatial Markov Chain Model for Virus Spread\n",
      "\n",
      "The spatial Markov Chain model is a sophisticated approach to understanding how viruses spread within a population. Here's a deeper look into its components and functions:\n",
      "\n",
      "- **Graph Representation:** The population is represented as a graph with nodes (individuals) and edges (connections/relationships). This allows for modeling the complex network of interactions through which a virus can spread<sup><a href=\"https://arxiv.org/pdf/2004.05635v1.pdf\" target=\"_blank\">[1]</a></sup>.\n",
      "\n",
      "- **Intensity of Interpersonal Contact:** The model assigns probabilities to the edges based on the intensity of contact between individuals. This reflects the real-world scenario where the likelihood of transmission varies with the nature and frequency of interactions<sup><a href=\"https://arxiv.org/pdf/2004.05635v1.pdf\" target=\"_blank\">[1]</a></sup>.\n",
      "\n",
      "- **Infectious Transfer by Chance:** The model incorporates randomness in the transmission process, acknowledging that not every contact between a susceptible individual and an infectious one results in transmission<sup><a href=\"https://arxiv.org/pdf/2004.05635v1.pdf\" target=\"_blank\">[1]</a></sup>.\n",
      "\n",
      "- **Lockdown Scenarios:** The model can simulate various public health interventions, such as lockdowns, and predict their impact on the spread of the virus. This helps in planning and evaluating containment strategies<sup><a href=\"https://arxiv.org/pdf/2004.05635v1.pdf\" target=\"_blank\">[1]</a></sup>.\n",
      "\n",
      "### Application in Covid-19 Pandemic\n",
      "\n",
      "- **Modeling Covid-19 Spread:** Researchers have developed a Markovian random-walk spatial extension of a quarantine-enhanced SIR model to measure and forecast the effect of factors like population density, testing rate, and social distancing on the spread of Covid-19<sup><a href=\"https://doi.org/10.1101/2020.04.12.20062927\" target=\"_blank\">[2]</a></sup>.\n",
      "\n",
      "- **Nonlinear Markov Chains Model:** A nonlinear Markov chains model was proposed to estimate daily new Covid-19 cases and examine the correlation between daily new cases and the number of deaths. This model was used to analyze the pandemic's behavior in various countries, providing a tool for short-term forecasting and understanding the pandemic's dynamics<sup><a href=\"http://medrxiv.org/cgi/content/short/2020.04.21.20073668v1\" target=\"_blank\">[3]</a></sup>.\n",
      "\n",
      "- **Public Health Interventions:** Markov models have been used to estimate the disease burden and the effects of various interventions, such as lockdowns, social distancing, and case isolation. These models help in determining the most effective strategies to mitigate the spread of Covid-19<sup><a href=\"http://medrxiv.org/cgi/content/short/2020.05.01.20087783v1\" target=\"_blank\">[4]</a></sup>.\n",
      "\n",
      "- **Understanding Intervention Impact:** The use of Markov chain models in the context of Covid-19 has provided insights into how supportive accommodation and other interventions can mitigate the impact of the pandemic on vulnerable populations, such as the homeless, and reduce the burden on healthcare systems<sup><a href=\"http://medrxiv.org/cgi/content/short/2020.05.04.20079301v1\" target=\"_blank\">[5]</a></sup>.\n",
      "\n",
      "In summary, Markov chains offer a robust framework for modeling the spread of viruses by capturing the complexity of human interactions and the stochastic nature of disease transmission. Their application in the Covid-19 pandemic has provided valuable insights for policymakers and health authorities to implement effective containment and mitigation strategies.\n",
      "\n",
      "References:\n",
      "1. [Spatial Markov Chain Model](https://arxiv.org/pdf/2004.05635v1.pdf)\n",
      "2. [Markovian Random-Walk Spatial Extension](https://doi.org/10.1101/2020.04.12.20062927)\n",
      "3. [Nonlinear Markov Chains Model](http://medrxiv.org/cgi/content/short/2020.04.21.20073668v1)\n",
      "4. [Public Health Interventions](http://medrxiv.org/cgi/content/short/2020.05.01.20087783v1)\n",
      "5. [Intervention Impact on Vulnerable Populations](http://medrxiv.org/cgi/content/short/2020.05.04.20079301v1)\n",
      "--\n",
      "Done agent: AgentExecutor\n"
     ]
    }
   ],
   "source": [
    "async for event in agent_with_chat_history.astream_events(\n",
    "    {\"question\": QUESTION}, config=config, version=\"v1\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chain_start\":\n",
    "        if (\n",
    "            event[\"name\"] == \"AgentExecutor\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print(\n",
    "                f\"Starting agent: {event['name']}\"\n",
    "            )\n",
    "    elif kind == \"on_chain_end\":\n",
    "        if (\n",
    "            event[\"name\"] == \"AgentExecutor\"\n",
    "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
    "            print()\n",
    "            print(\"--\")\n",
    "            print(\n",
    "                f\"Done agent: {event['name']}\"\n",
    "            )\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"\")\n",
    "    elif kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
    "        )\n",
    "    elif kind == \"on_tool_end\":\n",
    "        print(f\"Done tool: {event['name']}\")\n",
    "        # print(f\"Tool output was: {event['data'].get('output')}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41bba7-18df-4ab8-b4f6-60368160d348",
   "metadata": {},
   "source": [
    "#### Note: Try to run this last question with GPT3.5 and see how you are going to run out of token space in the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec64bf-fe24-42fc-8dde-4d478f0af21e",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We just built our first RAG BOT!.\n",
    "\n",
    "- We learned that **Agents + Tools are the best way to go about building Bots**. <br>\n",
    "- We converted the Azure Search retriever into a Tool using the function `GetDocSearchResults_Tool` in `utils.py`\n",
    "- We learned about the events API (Beta), one way to stream the answer from agents\n",
    "- We learned that for comprehensive, quality answers we will run out of space with GPT3.5. GPT4 then becomes necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56306506-d53d-4d43-93e2-a9300ed2a3ee",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "\n",
    "Now that we have a bot with one skill (Document Search), let's build more skills!. In the next Notebook, we are going to build an agent that can understand tabular data in csv file and can execute python commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2525a6d-a7cf-4a3f-a77b-e92de7cb407b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
