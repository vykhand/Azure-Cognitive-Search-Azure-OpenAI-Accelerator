{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to deal with complex/large Documents"
      ],
      "metadata": {},
      "id": "60ec6048-44e4-4118-b16a-9c4c9cc78a3b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous notebook, we developed a solution for various types of files and data formats commonly found in organizations, and this covers big majority of the use cases. However, you will find that there are issues when dealing with questions that require answers from complex files. The complexity of these files arises from their length and the way information is distributed within them. Large documents are always a challenge for Search Engines.\n",
        "\n",
        "One example of such complex files is Technical Specification Guides or Product Manuals, which can span hundreds of pages and contain information in the form of images, tables, forms, and more. Books are also complex due to their length and the presence of images or tables.\n",
        "\n",
        "These files are typically in PDF format. To better handle these PDFs, we need a smarter parsing method that treats each document as a special source and processes them page by page (1 page = 1 chunk). The objective is to obtain more accurate and faster answers from our system. Fortunately, there are usually not many of these types of documents in an organization, allowing us to make exceptions and treat them differently.\n",
        "\n",
        "If your use case is just PDFs, for example, you can just use [PyPDF library](https://pypi.org/project/pypdf/) or [Azure AI Document Intelligence SDK (former Form Recognizer)](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/overview?view=doc-intel-3.0.0), vectorize using OpenAI API and push the content to a vector-based index. And this is problably the simplest and fastest way to go.  However if your use case entails connecting to a datalake, or Sharepoint libraries or any other document data source with thousands of documents with multiple file types and that can change dynamically, then you would want to use the Ingestion and Document Cracking and AI-Enrichment capabilities of Azure Search engine, Notebooks 1-3, and avoid a lot of painful custom code. \n"
      ],
      "metadata": {},
      "id": "9281ac79-47cd-49d4-bdd4-7f5c173a947d"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "from typing import List\n",
        "\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "from common.utils import parse_pdf, read_pdf_files, text_to_base64\n",
        "from common.prompts import DOCSEARCH_PROMPT\n",
        "from common.utils import CustomAzureSearchRetriever\n",
        "\n",
        "\n",
        "from IPython.display import Markdown, HTML, display  \n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "    \n",
        "os.makedirs(\"data/books/\",exist_ok=True)\n",
        "    \n",
        "\n",
        "BLOB_CONTAINER_NAME = \"books\"\n",
        "BASE_CONTAINER_URL = \"https://datasetsgptsmartsearch.blob.core.windows.net/\" + BLOB_CONTAINER_NAME + \"/\"\n",
        "LOCAL_FOLDER = \"./data/books/\"\n",
        "\n",
        "os.makedirs(LOCAL_FOLDER,exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1709809630637
        }
      },
      "id": "15f6044e-463f-4988-bc46-a3c3d641c15c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1709809630720
        }
      },
      "id": "331692ba-b68e-4b99-9bae-5057da9a389d"
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = AzureOpenAIEmbeddings(deployment=os.environ[\"EMBEDDING_DEPLOYMENT_NAME\"], chunk_size=1) "
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1709809630815
        }
      },
      "id": "594ff0d4-56e3-4bed-843d-28c7a092069b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Manual Document Cracking with Push to Vector-based Index"
      ],
      "metadata": {},
      "id": "bb87c647-158c-4f85-b569-5b9462f06c83"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Within our demo storage account, we have a container named `books`, which holds 5 books of different lengths, languages, and complexities. Let's create a `cogsrch-index-books-vector` and load it with the pages of all these books.\n",
        "\n",
        "We begin by downloading these books to our local machine:"
      ],
      "metadata": {},
      "id": "75551868-1546-421b-a14e-e42618d88e61"
    },
    {
      "cell_type": "code",
      "source": [
        "books = [\"Azure_Cognitive_Search_Documentation.pdf\", \n",
        "         \"Boundaries_When_to_Say_Yes_How_to_Say_No_to_Take_Control_of_Your_Life.pdf\",\n",
        "         \"Fundamentals_of_Physics_Textbook.pdf\",\n",
        "         \"Made_To_Stick.pdf\",\n",
        "         \"Pere_Riche_Pere_Pauvre.pdf\"]"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1709728546025
        }
      },
      "id": "0999e24b-6a75-4fa1-9a5f-426cf0f0bdba"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's download the files to the local `./data/` folder:"
      ],
      "metadata": {},
      "id": "dd867b2f-b5a1-443c-aa0a-ce914a66b3c9"
    },
    {
      "cell_type": "code",
      "source": [
        "for book in tqdm(books):\n",
        "    book_url = BASE_CONTAINER_URL + book + os.environ['BLOB_SAS_TOKEN']\n",
        "    urllib.request.urlretrieve(book_url, LOCAL_FOLDER+ book)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 5/5 [00:07<00:00,  1.45s/it]\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1709728554902
        }
      },
      "id": "3554f0b7-fee8-4446-a155-5d22dc0f0888"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What to use: pyPDF or AI Documment Intelligence API (Form Recognizer)?\n",
        "\n",
        "In `utils.py` there is a **parse_pdf()** function. This utility function can parse local files using PyPDF library and can also parse local or from_url PDFs files using Azure AI Document Intelligence (Former Form Recognizer).\n",
        "\n",
        "If `form_recognizer=False`, the function will parse the PDF using the python pyPDF library, which 75% of the time does a good job.<br>\n",
        "\n",
        "Setting `form_recognizer=True`, is the best (and slower) parsing method using AI Documment Intelligence API (former known as Form Recognizer). You can specify the prebuilt model to use, the default is `model=\"prebuilt-document\"`. However, if you have a complex document with tables, charts and figures , you can try\n",
        "`model=\"prebuilt-layout\"`, and it will capture all of the nuances of each page (it takes longer of course).\n",
        "\n",
        "**Note: Many PDFs are scanned images. For example, any signed contract that was scanned and saved as PDF will NOT be parsed by pyPDF. Only AI Documment Intelligence API will work.**"
      ],
      "metadata": {},
      "id": "788cc0db-9dae-45f2-8943-2b6fa32fcc75"
    },
    {
      "cell_type": "code",
      "source": [
        "book_pages_map = dict()\n",
        "for book in books:\n",
        "    print(\"Extracting Text from\",book,\"...\")\n",
        "    \n",
        "    # Capture the start time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Parse the PDF\n",
        "    book_path = LOCAL_FOLDER+book\n",
        "    book_map = parse_pdf(file=book_path, form_recognizer=False, verbose=True)\n",
        "    book_pages_map[book]= book_map\n",
        "    \n",
        "    # Capture the end time and Calculate the elapsed time\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "\n",
        "    print(f\"Parsing took: {elapsed_time:.6f} seconds\")\n",
        "    print(f\"{book} contained {len(book_map)} pages\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Extracting Text from Azure_Cognitive_Search_Documentation.pdf ...\nExtracting text using PyPDF\nParsing took: 36.196573 seconds\nAzure_Cognitive_Search_Documentation.pdf contained 1947 pages\n\nExtracting Text from Boundaries_When_to_Say_Yes_How_to_Say_No_to_Take_Control_of_Your_Life.pdf ...\nExtracting text using PyPDF\nParsing took: 1.774712 seconds\nBoundaries_When_to_Say_Yes_How_to_Say_No_to_Take_Control_of_Your_Life.pdf contained 357 pages\n\nExtracting Text from Fundamentals_of_Physics_Textbook.pdf ...\nExtracting text using PyPDF\nParsing took: 108.938926 seconds\nFundamentals_of_Physics_Textbook.pdf contained 1450 pages\n\nExtracting Text from Made_To_Stick.pdf ...\nExtracting text using PyPDF\nParsing took: 8.216580 seconds\nMade_To_Stick.pdf contained 225 pages\n\nExtracting Text from Pere_Riche_Pere_Pauvre.pdf ...\nExtracting text using PyPDF\nParsing took: 1.134095 seconds\nPere_Riche_Pere_Pauvre.pdf contained 225 pages\n\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1709728860634
        }
      },
      "id": "c1c63a2f-7a53-4346-8a1f-483cfd159d34"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's check a random page of each book to make sure the parsing was done correctly:"
      ],
      "metadata": {},
      "id": "5de0a722-ae0c-4b57-802a-518f5d4d93fd"
    },
    {
      "cell_type": "code",
      "source": [
        "for bookname,bookmap in book_pages_map.items():\n",
        "    print(bookname,\"\\n\",\"chunk text:\",bookmap[random.randint(10, 50)][2][:120],\"...\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Azure_Cognitive_Search_Documentation.pdf \n chunk text: Other constructs, such as scoring profiles and C ORS options, can be added at any time.\nTo clearly understand what you c ...\n\nBoundaries_When_to_Say_Yes_How_to_Say_No_to_Take_Control_of_Your_Life.pdf \n chunk text: 42\nfrom people who act in destructive ways (Matt. 18:15–17; 1 Cor.\n5:9–13). We are not being unloving. Separating oursel ...\n\nFundamentals_of_Physics_Textbook.pdf \n chunk text: xx\nTutoring problem available (at instructor’s discretion) in WileyPLUSand WebAssignSSMWorked-out solution available in  ...\n\nMade_To_Stick.pdf \n chunk text: You use flags. You tap the existing memory terrain of your audience. \nYou use what's already there.  \nSIMPLE             ...\n\nPere_Riche_Pere_Pauvre.pdf \n chunk text: ~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ...\n\n"
        }
      ],
      "execution_count": 7,
      "metadata": {},
      "id": "f2a5d62f-b664-4662-a6c9-a1eb2a3c5e11"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see above, all books were parsed except `Pere_Riche_Pere_Pauvre.pdf` (this book is \"Rich Dad, Poor Dad\" written in French), why? Well, as we mentioned above, this book was scanned, so each page is an image and with a very unique font. We need a good PDF parser with good OCR capabilities in order to extract the content of this PDF. \n",
        "Let's try to parse this book again, but this time using Azure Document Intelligence API (former Form Recognizer)"
      ],
      "metadata": {},
      "id": "8bcdc1ee-71fc-49d2-8e7c-0964bc3a4370"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "book = \"Pere_Riche_Pere_Pauvre.pdf\"\n",
        "book_path = LOCAL_FOLDER+book\n",
        "book_map = parse_pdf(file=book_path, form_recognizer=True, model=\"prebuilt-document\",from_url=False, verbose=True)\n",
        "book_pages_map[book]= book_map"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Extracting text using Azure Document Intelligence\nCPU times: user 11.8 s, sys: 280 ms, total: 12.1 s\nWall time: 49.9 s\n"
        }
      ],
      "execution_count": 9,
      "metadata": {},
      "id": "801c6bc2-467c-4418-aa7e-ef89a1e20e1c"
    },
    {
      "cell_type": "code",
      "source": [
        "print(book,\"\\n\",\"chunk text:\",book_map[random.randint(10, 50)][2][:80],\"...\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Pere_Riche_Pere_Pauvre.pdf \n chunk text: règles différentes. Les employés sont perdants; les patrons et les investisseurs ...\n\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709730030443
        }
      },
      "id": "49e34506-513b-44d6-8dd5-75ee8023b0fb"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "book = \"Neal_Stephenson_Anathem.pdf\"\n",
        "book_path = LOCAL_FOLDER+book\n",
        "book_map = parse_pdf(file=book_path, form_recognizer=True, model=\"prebuilt-document\",from_url=False, verbose=True)\n",
        "book_pages_map[book]= book_map"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Extracting text using Azure Document Intelligence\nCPU times: user 51.9 s, sys: 1.04 s, total: 52.9 s\nWall time: 2min 31s\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "62f61eef-4bab-4d4f-99a5-0162a93d7f2e"
    },
    {
      "cell_type": "code",
      "source": [
        "print(book,\"\\n\",\"chunk text:\",book_map[random.randint(10, 50)][2][:80],\"...\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Neal_Stephenson_Anathem.pdf \n chunk text: \"All right, call them whatever you wish,\" I said, and then snorted, because I kn ...\n\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709730336742
        }
      },
      "id": "4d63eabe-05c7-4622-a5ed-12b9e1051353"
    },
    {
      "cell_type": "markdown",
      "source": [
        "As demonstrated above, Azure Document Intelligence proves to be superior to pyPDF. **For production scenarios, we strongly recommend using Azure Document Intelligence consistently**. When doing so, it's important to make a wise choice between the available models, such as \"prebuilt-document,\" \"prebuilt-layout,\" or others. You can find more information on model selection [HERE](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/choose-model-feature?view=doc-intel-3.0.0).\n"
      ],
      "metadata": {},
      "id": "9c279dfb-4fed-41b8-89e1-0ca2cefbcdc9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Vector-based index\n",
        "\n",
        "\n",
        "Now that we have the content of the book's chunks (each page of each book) in the dictionary `book_pages_map`, let's create the Vector index in our Azure Search Engine where this content is going to land"
      ],
      "metadata": {},
      "id": "7f5f9b7d-99e6-426d-a47e-343c7e8b492e"
    },
    {
      "cell_type": "code",
      "source": [
        "book_index_name = \"cogsrch-index-books\""
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1709809640577
        }
      },
      "id": "7d46e7c5-49c4-40f3-bb2d-79a9afeab4b1"
    },
    {
      "cell_type": "code",
      "source": [
        "### Create Azure Search Vector-based Index\n",
        "# Setup the Payloads header\n",
        "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
        "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1709809641972
        }
      },
      "id": "1b07e84b-d306-4bc9-9124-e64f252dd7b2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Please note the following points regarding the index:\n",
        "\n",
        "- The ParentKey field is absent.\n",
        "- The page_num field is present.\n",
        "\n",
        "The absence of the ParentKey field is due to the utilization of a PUSH method, rather than a PULL method. This approach indicates that we are not leveraging the integrated indexing provided by the Azure AI Search engine. Instead, we are engaging in the process of parsing, performing OCR, and manually creating and pushing the content along with its vectors.\n",
        "\n",
        "This manual parsing process involves the use of either, the pyPDF library, or the Azure Document Intelligence API. These APIs allow for the segmentation of content by page rather than by a specified number of characters, which is the method employed by the Azure AI search indexer. Consequently, this enables the inclusion of page_num as a field in our index."
      ],
      "metadata": {},
      "id": "2faab899-977b-40d0-b36e-26f75ac07e54"
    },
    {
      "cell_type": "markdown",
      "source": [
        "REST API version 2023-10-01-Preview supports external and internal vectorization. This Notebook assumes an external vectorization strategy. This API also supports:\n",
        "    \n",
        "- vectorSearch algorithms, hnsw and exhaustiveKnn nearest neighbors, with parameters for indexing and scoring.\n",
        "- vectorProfiles for multiple combinations of algorithm configurations.\n",
        "\n",
        "Vector search algorithms include **exhaustive k-nearest neighbors (KNN)** and **Hierarchical Navigable Small World (HNSW)**. Exhaustive KNN performs a brute-force search that scans the entire vector space. HNSW performs an approximate nearest neighbor (ANN) search. While KNN provides exact nearest neighbor search results with high accuracy, its computational cost and poor scalability make it impractical for large datasets or real-time applications. HNSW, on the other hand, offers a highly efficient and scalable solution for nearest neighbor searches by finding approximate nearest neighbors quickly, making it more suitable for large-scale and high-dimensional data applications.\n",
        "\n",
        "\n",
        "check [HERE](https://learn.microsoft.com/en-us/azure/search/vector-search-how-to-create-index?tabs=config-2023-10-01-Preview%2Crest-2023-11-01%2Cpush%2Cportal-check-index) for the details of the vector configuration."
      ],
      "metadata": {},
      "id": "75d63e68-69a5-4b3b-8eb0-86da02cb7230"
    },
    {
      "cell_type": "code",
      "source": [
        "index_payload = {\n",
        "    \"name\": book_index_name,\n",
        "    \"vectorSearch\": {\n",
        "        \"algorithms\": [  # We are showing here 3 types of search algorithms configurations that you can do\n",
        "             {\n",
        "                 \"name\": \"my-hnsw-config-1\",\n",
        "                 \"kind\": \"hnsw\",\n",
        "                 \"hnswParameters\": {\n",
        "                     \"m\": 4,\n",
        "                     \"efConstruction\": 400,\n",
        "                     \"efSearch\": 500,\n",
        "                     \"metric\": \"cosine\"\n",
        "                 }\n",
        "             },\n",
        "             {\n",
        "                 \"name\": \"my-hnsw-config-2\",\n",
        "                 \"kind\": \"hnsw\",\n",
        "                 \"hnswParameters\": {\n",
        "                     \"m\": 8,\n",
        "                     \"efConstruction\": 800,\n",
        "                     \"efSearch\": 800,\n",
        "                     \"metric\": \"cosine\"\n",
        "                 }\n",
        "             },\n",
        "             {\n",
        "                 \"name\": \"my-eknn-config\",\n",
        "                 \"kind\": \"exhaustiveKnn\",\n",
        "                 \"exhaustiveKnnParameters\": {\n",
        "                     \"metric\": \"cosine\"\n",
        "                 }\n",
        "             }\n",
        "        ],\n",
        "        \"vectorizers\": [\n",
        "            {\n",
        "                \"name\": \"openai\",\n",
        "                \"kind\": \"azureOpenAI\",\n",
        "                \"azureOpenAIParameters\":\n",
        "                {\n",
        "                    \"resourceUri\" : os.environ['AZURE_OPENAI_ENDPOINT'],\n",
        "                    \"apiKey\" : os.environ['AZURE_OPENAI_API_KEY'],\n",
        "                    \"deploymentId\" : os.environ['EMBEDDING_DEPLOYMENT_NAME']\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "        \"profiles\": [  # profiles is the diferent kind of combinations of algos and vectorizers\n",
        "            {\n",
        "             \"name\": \"my-vector-profile-1\",\n",
        "             \"algorithm\": \"my-hnsw-config-1\",\n",
        "             \"vectorizer\":\"openai\"\n",
        "            },\n",
        "            {\n",
        "             \"name\": \"my-vector-profile-2\",\n",
        "             \"algorithm\": \"my-hnsw-config-2\",\n",
        "             \"vectorizer\":\"openai\"\n",
        "            },\n",
        "            {\n",
        "             \"name\": \"my-vector-profile-3\",\n",
        "             \"algorithm\": \"my-eknn-config\",\n",
        "             \"vectorizer\":\"openai\"\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"semantic\": {\n",
        "        \"configurations\": [\n",
        "            {\n",
        "                \"name\": \"my-semantic-config\",\n",
        "                \"prioritizedFields\": {\n",
        "                    \"titleField\": {\n",
        "                        \"fieldName\": \"title\"\n",
        "                    },\n",
        "                    \"prioritizedContentFields\": [\n",
        "                        {\n",
        "                            \"fieldName\": \"chunk\"\n",
        "                        }\n",
        "                    ],\n",
        "                    \"prioritizedKeywordsFields\": []\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    \"fields\": [\n",
        "        {\"name\": \"id\", \"type\": \"Edm.String\", \"key\": \"true\", \"filterable\": \"true\" },\n",
        "        {\"name\": \"title\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
        "        {\"name\": \"chunk\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
        "        {\"name\": \"name\", \"type\": \"Edm.String\", \"searchable\": \"true\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
        "        {\"name\": \"location\", \"type\": \"Edm.String\", \"searchable\": \"false\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
        "        {\"name\": \"page_num\",\"type\": \"Edm.Int32\",\"searchable\": \"false\",\"retrievable\": \"true\"},\n",
        "        {\n",
        "            \"name\": \"chunkVector\",\n",
        "            \"type\": \"Collection(Edm.Single)\",\n",
        "            \"dimensions\": 1536,\n",
        "            \"vectorSearchProfile\": \"my-vector-profile-3\", # we picked profile 3 to show that this index uses eKNN vs HNSW (on prior notebooks)\n",
        "            \"searchable\": \"true\",\n",
        "            \"retrievable\": \"true\",\n",
        "            \"filterable\": \"false\",\n",
        "            \"sortable\": \"false\",\n",
        "            \"facetable\": \"false\"\n",
        "        }\n",
        "        \n",
        "    ],\n",
        "}\n",
        "\n",
        "r = requests.put(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + book_index_name,\n",
        "                 data=json.dumps(index_payload), headers=headers, params=params)\n",
        "print(r.status_code)\n",
        "print(r.ok)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "204\nTrue\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1709736586701
        }
      },
      "id": "2df4db6b-969b-4b91-963f-9334e17a4e3c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment to debug errors\n",
        "# r.text"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1709733875923
        }
      },
      "id": "36691ff0-c4c8-49d0-bfa8-3e076ece0ce5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload the Document chunks and its vectors to the Index"
      ],
      "metadata": {},
      "id": "3bc7dda9-4725-410e-9465-54f0298fc758"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code will iterate over each chunk of each book and use the Azure Search Rest API upload method to insert each document with its corresponding vector (using OpenAI embedding model) to the index."
      ],
      "metadata": {},
      "id": "d73e7600-7902-48d4-b199-9d9dc0a17aa0"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for bookname,bookmap in book_pages_map.items():\n",
        "    print(\"Uploading chunks from\",bookname)\n",
        "    for page in tqdm(bookmap):\n",
        "        try:\n",
        "            page_num = page[0] + 1\n",
        "            content = page[2]\n",
        "            book_url = BASE_CONTAINER_URL + bookname\n",
        "            upload_payload = {\n",
        "                \"value\": [\n",
        "                    {\n",
        "                        \"id\": text_to_base64(bookname + str(page_num)),\n",
        "                        \"title\": f\"{bookname}_page_{str(page_num)}\",\n",
        "                        \"chunk\": content,\n",
        "                        \"chunkVector\": embedder.embed_query(content if content!=\"\" else \"-------\"),\n",
        "                        \"name\": bookname,\n",
        "                        \"location\": book_url,\n",
        "                        \"page_num\": page_num,\n",
        "                        \"@search.action\": \"upload\"\n",
        "                    },\n",
        "                ]\n",
        "            }\n",
        "\n",
        "            r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + book_index_name + \"/docs/index\",\n",
        "                                 data=json.dumps(upload_payload), headers=headers, params=params)\n",
        "            if r.status_code != 200:\n",
        "                print(r.status_code)\n",
        "                print(r.text)\n",
        "        except Exception as e:\n",
        "            print(\"Exception:\",e)\n",
        "            print(content)\n",
        "            continue"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading chunks from Azure_Cognitive_Search_Documentation.pdf\nUploading chunks from Boundaries_When_to_Say_Yes_How_to_Say_No_to_Take_Control_of_Your_Life.pdf\nUploading chunks from Fundamentals_of_Physics_Textbook.pdf\nUploading chunks from Made_To_Stick.pdf\nUploading chunks from Pere_Riche_Pere_Pauvre.pdf\nUploading chunks from Neal_Stephenson_Anathem.pdf\nCPU times: user 4min 32s, sys: 4.91 s, total: 4min 37s\nWall time: 26min 9s\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 1947/1947 [05:28<00:00,  5.93it/s]\n100%|██████████| 357/357 [01:16<00:00,  4.64it/s]\n100%|██████████| 1450/1450 [13:31<00:00,  1.79it/s]\n100%|██████████| 225/225 [01:11<00:00,  3.15it/s]\n100%|██████████| 225/225 [01:05<00:00,  3.44it/s]\n100%|██████████| 752/752 [03:35<00:00,  3.50it/s]\n"
        }
      ],
      "execution_count": 17,
      "metadata": {},
      "id": "f5c8aa55-1b60-4057-93db-0d4a89993a57"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query the Index"
      ],
      "metadata": {},
      "id": "715cddcf-af7b-4006-a047-853fc7a66be3"
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"what normally rich dad do that is different from poor dad?\"\n",
        "# QUESTION = \"Tell me a summary of the book Boundaries\"\n",
        "# QUESTION = \"Dime que significa la radiacion del cuerpo negro\"\n",
        "# QUESTION = \"what is the acronym of the main point of Made to Stick book\"\n",
        "# QUESTION = \"Tell me a python example of how do I push documents with vectors to an index using the python SDK?\"\n",
        "# QUESTION = \"who won the soccer worldcup in 1994?\" # this question should have no answer"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1709809699178
        }
      },
      "id": "8b408798-5527-44ca-9dba-cad2ee726aca"
    },
    {
      "cell_type": "code",
      "source": [
        "indexes = [book_index_name]\n",
        "k=20 # in this index k corresponds to the top pages as well"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1709809699746
        }
      },
      "id": "1b182ade-0ddd-47a1-b1eb-2cbf435c317f"
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = CustomAzureSearchRetriever(indexes=[book_index_name], topK=k, reranker_threshold=1)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1709809700567
        }
      },
      "id": "d50eecb2-ce26-4127-a62b-79735b937046"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: that we are picking a larger k=20 since these chunks are NOT of 5000 chars each like prior notebooks, but instead each page is a chunk."
      ],
      "metadata": {},
      "id": "fdd2f3f2-2d66-4bd4-b90b-d30970b71af4"
    },
    {
      "cell_type": "code",
      "source": [
        "COMPLETION_TOKENS = 2500\n",
        "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT35_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS).configurable_alternatives(\n",
        "    ConfigurableField(id=\"model\"),\n",
        "    default_key=\"gpt35\",\n",
        "    gpt4=AzureChatOpenAI(deployment_name=os.environ[\"GPT4_DEPLOYMENT_NAME\"], temperature=0, max_tokens=COMPLETION_TOKENS),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1709809701816
        }
      },
      "id": "410ff796-dab1-4817-a3a5-82eeff6c0c57"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In `utils.py` we created the **CustomAzureSearchRetriever** class that we will use going forward"
      ],
      "metadata": {},
      "id": "c33c2851-08c5-4e7c-ba7b-4655a6021e1e"
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    {\n",
        "        \"context\": itemgetter(\"question\") | retriever, # Passes the question to the retriever and the results are assign to context\n",
        "        \"question\": itemgetter(\"question\")\n",
        "    }\n",
        "    | DOCSEARCH_PROMPT  # Passes the 4 variables above to the prompt template\n",
        "    | llm   # Passes the finished prompt to the LLM\n",
        "    | StrOutputParser()  # converts the output (Runnable object) to the desired output (string)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1709809703557
        }
      },
      "id": "26f47c69-44d8-48e3-974e-7989b4a8b7c5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With GPT 3.5"
      ],
      "metadata": {},
      "id": "765df250-af7f-46c9-8d7a-15c0522969ec"
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in chain.with_config(configurable={\"model\": \"gpt35\"}).stream({\"question\": QUESTION}):\n",
        "    print(chunk, end=\"\", flush=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "According to the extracted parts, the rich dad and the poor dad have different approaches and perspectives when it comes to money and financial matters.\n\nThe rich dad believes in making money work for him, while the poor dad believes in working for money<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Pere_Riche_Pere_Pauvre.pdf?source=1.7045036554336548\" target=\"_blank\">[1]</a></sup>. The rich dad emphasizes the importance of financial education and learning how to manage money effectively<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Pere_Riche_Pere_Pauvre.pdf?source=1.594975471496582\" target=\"_blank\">[2]</a></sup>. He encourages his children to learn about the fundamentals of money and how to make it work for them<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Pere_Riche_Pere_Pauvre.pdf?source=1.594975471496582\" target=\"_blank\">[2]</a></sup>.\n\nIn contrast, the poor dad focuses on traditional education and advises his children to study hard, get good grades, and find a secure job with good benefits<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Pere_Riche_Pere_Pauvre.pdf?source=1.594975471496582\" target=\"_blank\">[2]</a></sup>. He believes that financial security comes from working for a stable company and relying on a steady paycheck<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Pere_Riche_Pere_Pauvre.pdf?source=1.594975471496582\" target=\"_blank\">[2]</a></sup>.\n\nThe rich dad also emphasizes the importance of taking risks and having a mindset focused on creating wealth<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Pere_Riche_Pere_Pauvre.pdf?source=1.4486825466156006\" target=\"_blank\">[3]</a></sup>. He encourages his children to think creatively, invest in assets that generate income, and become financially independent<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Pere_Riche_Pere_Pauvre.pdf?source=1.4486825466156006\" target=\"_blank\">[3]</a></sup>.\n\nIn summary, the rich dad focuses on financial education, making money work for him, taking risks, and investing in assets, while the poor dad emphasizes traditional education, working for money, and relying on a steady paycheck."
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1709736641590
        }
      },
      "id": "73f34192-519d-45b9-a0e2-a8b2de51ee1e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With GPT 4"
      ],
      "metadata": {},
      "id": "d4a8761d-2c1e-4369-b7c4-c3571a0793e9"
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in chain.with_config(configurable={\"model\": \"gpt4\"}).stream(\n",
        "    {\"question\": QUESTION, \"language\": \"English\"}):\n",
        "    print(chunk, end=\"\", flush=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "According to the book \"Père riche, père pauvre\" by Robert T. Kiyosaki and Sharon L. Lechter, there are several key differences in the mindset and actions between the \"rich dad\" and the \"poor dad\":\n\n1. **Attitude Towards Money and Work**: The rich dad teaches that the poor and the middle class work for money, while the rich have money work for them. This reflects a fundamental difference in approach to earning and managing money<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Pere_Riche_Pere_Pauvre.pdf\" target=\"_blank\">[1]</a></sup>.\n\n2. **Financial Education**: The rich dad emphasizes the importance of financial education and understanding how money works. He believes in studying to become rich and understanding the functioning of money, rather than just studying for good grades and a secure job<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Pere_Riche_Pere_Pauvre.pdf\" target=\"_blank\">[3]</a></sup>.\n\n3. **Managing Fear and Risk**: The rich dad teaches how to manage fear and risk when it comes to money. He believes that it is normal to be fearful but one can still become rich by learning to manage that fear<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Pere_Riche_Pere_Pauvre.pdf\" target=\"_blank\">[5]</a></sup>.\n\n4. **Financial Independence**: The rich dad values financial independence and is against the mentality of relying on a company or government for financial security. He believes in creating investments rather than saving a few dollars<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Pere_Riche_Pere_Pauvre.pdf\" target=\"_blank\">[29]</a></sup>.\n\n5. **Assets vs. Liabilities**: The rich dad teaches the importance of knowing the difference between assets and liabilities and encourages acquiring assets. He believes that rich people acquire assets, while the poor and middle class acquire liabilities thinking they are assets<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Pere_Riche_Pere_Pauvre.pdf\" target=\"_blank\">[29]</a></sup>.\n\n6. **Ownership and Control**: The rich dad encourages owning businesses and investments rather than being satisfied with a secure job in a company. He believes in the power of owning the ladder of success rather than just climbing it<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Pere_Riche_Pere_Pauvre.pdf\" target=\"_blank\">[126]</a></sup>.\n\n7. **Paying Oneself First**: The rich dad practices the principle of paying oneself first before paying creditors, even if it means being short of money. He prioritizes his asset column over paying the government<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Pere_Riche_Pere_Pauvre.pdf\" target=\"_blank\">[196]</a></sup>.\n\nThese principles highlight the different philosophies and actions that distinguish the \"rich dad\" approach from the \"poor dad\" approach to money and wealth-building."
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1709736812539
        }
      },
      "id": "14b77511-b178-4c9b-9fa5-fdddb0d3e586"
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"What is the difference between Procians and Halikarnians?\"\n",
        "for chunk in chain.with_config(configurable={\"model\": \"gpt4\"}).stream(\n",
        "    {\"question\": QUESTION, \"language\": \"English\"}):\n",
        "    print(chunk, end=\"\", flush=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The Procians and Halikaarnians represent two distinct philosophical and theoretical schools within the world of Arbre, as depicted in Neal Stephenson's \"Anathem.\"\n\n**Procians** are generally associated with Saunt Proc, a metatheorician from the late Praxic Age who is considered the standard-bearer of the theoretical lineage traceable to the Sphenics. Procians are described as being of, or relating to, Saunt Proc or any of the Orders that claim descent from the Syntactic Faculties, which emerged in the early post-Reconstitution maths. They are often seen as natural opponents of the Halikaarnians and are characterized by a suspicion of the idea of absolute truth. They are more inclined to classify the story of Cnoons as a fairy tale and pay lip service to Hylaea, not because they believe in the Hylaean Theoric World (HTW) as a reality, but because of what she symbolizes and because she wasn't as extreme as her sister. The Procians are also linked to the Syntactic Faculties, which believed that language, theorics, etc., were essentially games played with symbols devoid of semantic content, a view traceable to the ancient Sphenics<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Neal_Stephenson_Anathem.pdf\" target=\"_blank\">[1]</a></sup><sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Neal_Stephenson_Anathem.pdf\" target=\"_blank\">[6]</a></sup><sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Neal_Stephenson_Anathem.pdf\" target=\"_blank\">[7]</a></sup>.\n\n**Halikaarnians**, on the other hand, are associated with Saunt Halikaarn, also from the late Praxic Age, who clashed with Proc. Halikaarnians claim descent from the Semantic Faculties and are frequently seen as natural opponents of the Procians and Faanians. They are the standard-bearers of the school of theorics promulgated by Protas and Thelenes, carried forward by Evenedric and the Semantic Faculties. This school is characterized by the belief that symbols could bear actual semantic content, and they seek truth in pure theorics. The Halikaarnians are more aligned with the traditional view of Protism, which posits that the human mind is capable of perceiving pure ideas from another realm of existence known as the Hylaean Theoric World<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Neal_Stephenson_Anathem.pdf\" target=\"_blank\">[1]</a></sup><sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Neal_Stephenson_Anathem.pdf\" target=\"_blank\">[5]</a></sup>.\n\nIn summary, the main difference between Procians and Halikaarnians lies in their philosophical stance towards truth, theorics, and the existence of the Hylaean Theoric World. Procians are more skeptical of absolute truths and the reality of the HTW, viewing theorics as symbolic and syntactic, while Halikaarnians believe in the semantic content of symbols and the existence of a realm where pure ideas reside, which the human mind can access<sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Neal_Stephenson_Anathem.pdf\" target=\"_blank\">[1]</a></sup><sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Neal_Stephenson_Anathem.pdf\" target=\"_blank\">[5]</a></sup><sup><a href=\"https://datasetsgptsmartsearch.blob.core.windows.net/books/Neal_Stephenson_Anathem.pdf\" target=\"_blank\">[6]</a></sup>."
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1709809911647
        }
      },
      "id": "d07a5f70-3547-42e0-8c02-53cc3efd8a4e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "In this notebook we learned how to deal with complex and large Documents and make them available for Q&A over them using [Hybrid Search](https://learn.microsoft.com/en-us/azure/search/search-get-started-vector#hybrid-search) (text + vector search).\n",
        "\n",
        "We also learned the power of Azure Document Inteligence API and why it is recommended for production scenarios where manual Document parsing (instead of Azure Search Indexer Document Cracking) is necessary.\n",
        "\n",
        "Using Azure Cognitive Search with its Vector capabilities and hybrid search features eliminates the need for other vector databases such as Weaviate, Qdrant, Milvus, Pinecone, and so on.\n"
      ],
      "metadata": {},
      "id": "3941796c-7655-4888-a358-8a62e380bd7e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEXT\n",
        "So far we have learned how to use OpenAI vectors and completion APIs in order to get an excelent answer from our documents stored in Azure AI Search. This is the backbone for a GPT Smart Search Engine.\n",
        "\n",
        "However, we are missing something: **How to have a conversation with this engine?**\n",
        "\n",
        "On the next Notebook, we are going to understand the concept of **memory**. This is necessary in order to have a chatbot that can establish a conversation with the user. Without memory, there is no real conversation."
      ],
      "metadata": {},
      "id": "85d9a7d1-f029-416b-8eb2-00a8afb9151d"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "0ed733fb-dec4-4a8f-bff0-c7cbbcc0328e"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}